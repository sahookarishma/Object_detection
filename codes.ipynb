{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO(\n",
      "  (backbone): YOLOBackbone(\n",
      "    (layers): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): ConvBlock(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): ConvBlock(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (6): ConvBlock(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): ConvBlock(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): ConvBlock(\n",
      "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (head): YOLOHead(\n",
      "    (detector): Conv2d(1024, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"A block of Conv2D -> BatchNorm -> ReLU.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class YOLOBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLOBackbone, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            ConvBlock(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            ConvBlock(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            ConvBlock(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            ConvBlock(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            ConvBlock(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            ConvBlock(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2),  # 14 -> 7\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class YOLOHead(nn.Module):\n",
    "    def __init__(self, grid_size, num_classes, num_anchors):\n",
    "        super(YOLOHead, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors = num_anchors\n",
    "        self.detector = nn.Conv2d(1024, num_anchors * (5 + num_classes), kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.detector(x).permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "\n",
    "\n",
    "class YOLO(nn.Module):\n",
    "    def __init__(self, grid_size=7, num_classes=2, num_anchors=3):\n",
    "        super(YOLO, self).__init__()\n",
    "        self.backbone = YOLOBackbone()\n",
    "        self.head = YOLOHead(grid_size, num_classes, num_anchors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        predictions = self.head(features)\n",
    "        return predictions\n",
    "\n",
    "# Example usage\n",
    "model = YOLO(grid_size=7, num_classes=2, num_anchors=3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor Boxes: [[0.07071068 0.14142136]\n",
      " [0.1        0.1       ]\n",
      " [0.14142136 0.07071068]\n",
      " [0.14142136 0.28284271]\n",
      " [0.2        0.2       ]\n",
      " [0.28284271 0.14142136]\n",
      " [0.28284271 0.56568542]\n",
      " [0.4        0.4       ]\n",
      " [0.56568542 0.28284271]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_anchors(scales, ratios):\n",
    "    \"\"\"Generates anchor boxes for given scales and aspect ratios.\"\"\"\n",
    "    anchors = []\n",
    "    for scale in scales:\n",
    "        for ratio in ratios:\n",
    "            width = scale * np.sqrt(ratio)\n",
    "            height = scale / np.sqrt(ratio)\n",
    "            anchors.append((width, height))\n",
    "    return np.array(anchors)\n",
    "\n",
    "# Example: Scales and ratios\n",
    "scales = [0.1, 0.2, 0.4]\n",
    "ratios = [0.5, 1, 2]\n",
    "anchors = generate_anchors(scales, ratios)\n",
    "print(\"Anchor Boxes:\", anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_yolo_format(width, height, bbox):\n",
    "    \"\"\"Converts absolute bounding box to YOLO format.\"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    x_center = (x_min + x_max) / 2 / width\n",
    "    y_center = (y_min + y_max) / 2 / height\n",
    "    box_width = (x_max - x_min) / width\n",
    "    box_height = (y_max - y_min) / height\n",
    "    return [x_center, y_center, box_width, box_height]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_loss(predictions, targets, num_classes=2, lambda_coord=5, lambda_noobj=0.5):\n",
    "    \"\"\"\n",
    "    Computes YOLO loss.\n",
    "    - predictions: Predicted tensor of shape [batch_size, S, S, B*(5+C)]\n",
    "    - targets: Ground truth tensor of shape [batch_size, S, S, B*(5+C)]\n",
    "    \"\"\"\n",
    "    batch_size, S, S, total_features = predictions.shape\n",
    "    B = 3  # number of anchors\n",
    "    C = num_classes\n",
    "    \n",
    "    # Reshape predictions and targets to separate anchors\n",
    "    predictions = predictions.view(batch_size, S, S, B, 5 + C)\n",
    "    targets = targets.view(batch_size, S, S, B, 5 + C)\n",
    "    \n",
    "    # Unpack predictions and targets\n",
    "    pred_boxes = predictions[..., :4]  # [batch_size, S, S, B, 4]\n",
    "    pred_conf = predictions[..., 4]    # [batch_size, S, S, B]\n",
    "    pred_classes = predictions[..., 5:] # [batch_size, S, S, B, C]\n",
    "    \n",
    "    target_boxes = targets[..., :4]    # [batch_size, S, S, B, 4]\n",
    "    target_conf = targets[..., 4]      # [batch_size, S, S, B]\n",
    "    target_classes = targets[..., 5:]  # [batch_size, S, S, B, C]\n",
    "    \n",
    "    # Localization Loss (only for cells with objects)\n",
    "    obj_mask = target_conf > 0\n",
    "    box_loss = lambda_coord * torch.sum(obj_mask.unsqueeze(-1) * (pred_boxes - target_boxes) ** 2)\n",
    "\n",
    "    # Confidence Loss\n",
    "    obj_loss = torch.sum(obj_mask * (pred_conf - target_conf) ** 2)\n",
    "    noobj_loss = lambda_noobj * torch.sum((~obj_mask) * pred_conf ** 2)\n",
    "\n",
    "    # Classification Loss (only for cells with objects)\n",
    "    class_loss = torch.sum(obj_mask.unsqueeze(-1) * (pred_classes - target_classes) ** 2)\n",
    "\n",
    "    # Total Loss\n",
    "    total_loss = box_loss + obj_loss + noobj_loss + class_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_yolo_targets(boxes, S=7, B=3, C=2):\n",
    "    \"\"\"\n",
    "    boxes: tensor of shape [num_boxes, 5] (class, x_center, y_center, width, height)\n",
    "    Returns: tensor of shape [S, S, B*5 + B*C] = [S, S, 21] for B=3, C=2\n",
    "    \"\"\"\n",
    "    target = torch.zeros((S, S, B*5 + B*C))  # Changed from B*5 + C to B*5 + B*C\n",
    "    if len(boxes) == 0:\n",
    "        return target\n",
    "    \n",
    "    for box in boxes:\n",
    "        class_idx, x, y, w, h = box\n",
    "        # Convert to Python scalars\n",
    "        class_idx = int(class_idx.item()) if hasattr(class_idx, 'item') else int(class_idx)\n",
    "        x = float(x.item()) if hasattr(x, 'item') else float(x)\n",
    "        y = float(y.item()) if hasattr(y, 'item') else float(y)\n",
    "        w = float(w.item()) if hasattr(w, 'item') else float(w)\n",
    "        h = float(h.item()) if hasattr(h, 'item') else float(h)\n",
    "        \n",
    "        i, j = int(y * S), int(x * S)  # grid cell indices\n",
    "        if i >= S: i = S-1\n",
    "        if j >= S: j = S-1\n",
    "        if i < 0: i = 0\n",
    "        if j < 0: j = 0\n",
    "        \n",
    "        # Fill all anchors for this cell\n",
    "        for anchor_idx in range(B):\n",
    "            # Box coordinates and objectness (5 values per anchor)\n",
    "            anchor_offset = anchor_idx * 5\n",
    "            target[i, j, anchor_offset:anchor_offset+5] = torch.tensor([x, y, w, h, 1])\n",
    "            \n",
    "            # Class probabilities (C values per anchor)\n",
    "            class_offset = B*5 + anchor_idx * C\n",
    "            if class_idx < C:\n",
    "                target[i, j, class_offset + class_idx] = 1  # one-hot class for this anchor\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([8, 7, 7, 21])\n",
      "Targets shape: torch.Size([8, 7, 7, 21])\n",
      "Loss computed successfully: 736.7039794921875\n"
     ]
    }
   ],
   "source": [
    "# Test shapes\n",
    "for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "    if batch_idx == 0:  # Only test first batch\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        predictions = model(images)\n",
    "        \n",
    "        print(\"Predictions shape:\", predictions.shape)\n",
    "        print(\"Targets shape:\", targets.shape)\n",
    "        \n",
    "        # Test loss function\n",
    "        loss = yolo_loss(predictions, targets, num_classes=2)\n",
    "        print(\"Loss computed successfully:\", loss.item())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class YOLODataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, class_to_idx, transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transforms = transforms\n",
    "        self.class_to_idx = class_to_idx  # e.g., {\"cat\": 0, \"dog\": 1}\n",
    "        self.images = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.images[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_filename)\n",
    "        label_filename = os.path.splitext(img_filename)[0] + \".xml\"\n",
    "        label_path = os.path.join(self.label_dir, label_filename)\n",
    "\n",
    "        # Load image using PIL\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        width, height = image.size\n",
    "\n",
    "        # Parse XML and extract boxes\n",
    "        boxes = []\n",
    "        tree = ET.parse(label_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for obj in root.findall('object'):\n",
    "            label = obj.find('name').text.lower().strip()\n",
    "            class_idx = self.class_to_idx[label]\n",
    "\n",
    "            bbox = obj.find('bndbox')\n",
    "            x_min = float(bbox.find('xmin').text)\n",
    "            y_min = float(bbox.find('ymin').text)\n",
    "            x_max = float(bbox.find('xmax').text)\n",
    "            y_max = float(bbox.find('ymax').text)\n",
    "\n",
    "            # Convert to YOLO format: [class, x_center, y_center, width, height]\n",
    "            x_center = (x_min + x_max) / 2 / width\n",
    "            y_center = (y_min + y_max) / 2 / height\n",
    "            box_width = (x_max - x_min) / width\n",
    "            box_height = (y_max - y_min) / height\n",
    "\n",
    "            boxes.append([class_idx, x_center, y_center, box_width, box_height])\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "                # Handle empty boxes case\n",
    "        if len(boxes) == 0:\n",
    "            encoded_target = encode_yolo_targets(torch.empty(0, 5), S=7, B=3, C=2)\n",
    "        else:\n",
    "            encoded_target = encode_yolo_targets(torch.tensor(boxes), S=7, B=3, C=2)\n",
    "        \n",
    "        return image, encoded_target\n",
    "\n",
    "\n",
    "class_to_idx = {\"cat\": 0, \"dog\": 1} \n",
    "# Example: Initialize DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "train_dataset = YOLODataset(img_dir=r\"C:\\Users\\Harshal\\playground\\object-detection\\dataset\\images\", label_dir=r\"C:\\Users\\Harshal\\playground\\object-detection\\dataset\\annotation\", class_to_idx=class_to_idx, transforms=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x177e2735c90>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO(\n",
      "  (backbone): YOLOBackbone(\n",
      "    (layers): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): ConvBlock(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): ConvBlock(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (6): ConvBlock(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): ConvBlock(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): ConvBlock(\n",
      "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (head): YOLOHead(\n",
      "    (detector): Conv2d(1024, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Output shape: torch.Size([1, 7, 7, 21])\n"
     ]
    }
   ],
   "source": [
    "# Reinitialize model with correct architecture\n",
    "model = YOLO(grid_size=7, num_classes=2, num_anchors=3)\n",
    "print(model)\n",
    "\n",
    "# Test the output shape\n",
    "x = torch.randn(1, 3, 448, 448)\n",
    "output = model(x)\n",
    "print(\"Output shape:\", output.shape)  # Should be [1, 7, 7, 75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]: 100%|██████████| 3/3 [00:07<00:00,  2.60s/it, loss=34.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 484.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]: 100%|██████████| 3/3 [00:06<00:00,  2.26s/it, loss=56.3]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 1119.0332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]: 100%|██████████| 3/3 [00:06<00:00,  2.15s/it, loss=31.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 198.5142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]: 100%|██████████| 3/3 [00:06<00:00,  2.32s/it, loss=15.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 215.1785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]: 100%|██████████| 3/3 [00:06<00:00,  2.30s/it, loss=10.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 71.1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]: 100%|██████████| 3/3 [00:12<00:00,  4.29s/it, loss=6.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 65.1223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]: 100%|██████████| 3/3 [00:15<00:00,  5.27s/it, loss=4.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 53.2828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]: 100%|██████████| 3/3 [00:16<00:00,  5.44s/it, loss=5.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 34.6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]: 100%|██████████| 3/3 [00:14<00:00,  4.77s/it, loss=8.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 26.4058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]: 100%|██████████| 3/3 [00:06<00:00,  2.30s/it, loss=8.03]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 27.9706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 2\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = YOLO(grid_size=7, num_classes=num_classes, num_anchors=3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Move model to train mode\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (images, targets) in enumerate(loop):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(images)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = yolo_loss(predictions, targets, num_classes=num_classes)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update tqdm loop description\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'yoloObjectdetection_cat_dog_model.pth')\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
