# -*- coding: utf-8 -*-
"""Image_classification and object_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19bJAh3ctrNuuVK07IC7P-Hjma7eQGJ_c
"""

import tensorflow as tf
from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input
# from tensorflow.keras import model
import pandas as pd

!pwd

df_train = pd.read_csv('/content/sample_data/mnist_train_small.csv', header= None, sep=',')
df_test = pd.read_csv('/content/sample_data/mnist_test.csv', header= None, sep=',')

# df.iloc[:, 1:]
print(df_train.shape)
print(df_test.shape)

train = df_train.iloc[:, 1:].to_numpy()
test = df_test.iloc[:, 1:].to_numpy()
y_train = df_train.iloc[:, 0].to_numpy()
y_test = df_test.iloc[:, 0].to_numpy()

# Check shape
print(train.shape)
print(test.shape)
print(y_train.shape)
print(y_test.shape)

model = tf.keras.models.Sequential([
    Input(shape=(784,)),
    Dense(512, activation='relu'),
    Dense(256, activation='relu'),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# model.build(input_shape=(32, 784))

model.summary()

model.fit(train, y_train, epochs=10, validation_data=(test, y_test))

model.predict(test).argmax(axis=1)

# accuracy
# Explain
# model.evaluate(test, y_test)

model.evaluate(test, y_test)

# prompt: # Explain
# # model.evaluate(test, y_test)

# Explain
# model.evaluate(test, y_test)

# model.evaluate(test, y_test) calculates the loss and metrics for the model on the provided test data.
# In this specific case, 'test' is the numpy array containing the test image pixel data,
# and 'y_test' is the numpy array containing the true labels for the test data.
# The 'metrics' defined during the model's compilation ('accuracy' in this case)
# will be calculated and returned along with the loss.
# The function returns a list containing the loss and the values of the specified metrics.
# For example, if the model was compiled with loss and accuracy, it will return [loss_value, accuracy_value].
model.evaluate(test, y_test)

class Calling:
  def __init__(self, name, age):
    self.name = name
    self.age = age
  def greet(self):
    print('Hello ', self.name)

obj1 = Calling('karishma', 9)

obj1.greet()

obj1.age

Obj2 = Calling('ram', 10)

Obj2.greet()

"""###OBJECT DETECTION###

Intersection over union method
"""

import torch
def intersection_over_union(boxes_preds, boxes_labels, box_format):
  ### boxes_preds shape is (N, 4) where n is the number of box

  if box_format == "midpoint":
    box1_x1 = boxes_preds[...,0:1] - boxes_preds[...,2:3] / 2
    box1_y1 = boxes_preds[...,1:2] - boxes_preds[...,3:4] / 2
    box1_x2 = boxes_preds[...,0:1] + boxes_preds[...,2:3] / 2
    box1_y2 = boxes_preds[...,1:2] + boxes_preds[...,3:4] / 2
    box2_x1 = boxes_labels[...,0:1] - boxes_labels[...,2:3] / 2
    box2_y1 = boxes_labels[...,1:2] - boxes_labels[...,3:4] / 2
    box2_x2 = boxes_labels[...,0:1] + boxes_labels[...,2:3] / 2
    box2_y2 = boxes_labels[...,1:2] + boxes_labels[...,3:4] / 2

  elif box_format == "corners":
    box1_x1 = boxes_preds[...,0:1]
    box1_y1 = boxes_preds[...,1:2]
    box1_x2 = boxes_preds[...,2:3]
    box1_y2 = boxes_preds[...,3:4]
    box2_x1 = boxes_labels[...,0:1]
    box2_y1 = boxes_labels[...,1:2]
    box2_x2 = boxes_labels[...,2:3]
    box2_y2 = boxes_labels[...,3:4]


  x1 = torch.max(box1_x1, box2_x1)
  y1 = torch.max(box1_y1, box2_y1)
  x2 = torch.min(box1_x2, box2_x2)
  y2 = torch.min(box1_y2, box2_y2)

  ## .clamp(0) is for the case when the bounding boxes do not intersect. then one of the value should be zero to make the whole IoU = zero
  intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)


  box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))
  box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))
  Iou = intersection / (box1_area + box2_area - intersection + 1e-6)

  return Iou

# Define two boxes: [x1, y1, x2, y2]
boxes_preds = torch.tensor([10, 10, 50, 50], dtype=torch.float32)
boxes_labels = torch.tensor([30, 30, 70, 70], dtype=torch.float32)

iou = intersection_over_union(boxes_preds, boxes_labels, box_format='corners')
print(iou)

boxes_preds = torch.tensor([
    [10, 10, 50, 50],
    [30, 30, 60, 60]
], dtype=torch.float32)

boxes_labels = torch.tensor([
    [20, 20, 40, 40],
    [35, 35, 55, 55]
], dtype=torch.float32)

ious = intersection_over_union(boxes_preds, boxes_labels, box_format="corners")
print("IoUs for all box pairs:", ious)

preds = torch.tensor([[40, 55, 40, 50]], dtype=torch.float32)  # x_center, y_center, w, h
labels = torch.tensor([[65, 75, 50, 50]], dtype=torch.float32)

print(intersection_over_union(preds, labels, box_format="midpoint"))

"""Non max suppression

"""

import torch
def non_max_suppression(bboxes, iou_thresholds, threshold, box_format ="corners"):
  assert type(bboxes) == list
  bboxes = [box for box in bboxes if box[1]> threshold]
  bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)
  nms_boxes = []

  while bboxes:
    chosen_box = bboxes.pop(0)
    nms_boxes.append(chosen_box)

    bboxes = [
        box
        for box in bboxes
        if box[0] != chosen_box[0]
        or intersection_over_union(
            torch.tensor(chosen_box[2:]),
            torch.tensor(box[2:]),
            box_format=box_format
        ) < iou_thresholds
    ]

    return nms_boxes

boxes = [
    [0, 0.9, 10, 10, 50, 50],  # class, confidence, x1, y1, x2, y2
    [0, 0.8, 12, 12, 48, 48],
    [0, 0.7, 100, 100, 150, 150],
    [1, 0.95, 10, 10, 50, 50]  # different class â†’ not suppressed
]

result = non_max_suppression(boxes, iou_thresholds=0.5, threshold=0.6)
for box in result:
    print(f"Kept Box: {box}")

import torch
from collections import Counter

def mean_average_precision(pred_boxes, true_boxes, iou_threshold=0.5, box_format="corners", num_classes=20):
  average_precisions = []
  epsilon = 1e-6

  for c in range(num_classes):
    detections = []
    ground_truths = []

    for detection in pred_boxes:
      if detection[1] == c:
        detections.append(detection)

    for true_box in true_boxes:
      if true_box[1] == c:
        ground_truths.append(true_box)

    ##img 0 has 3 boxes
    ##img 1 has 5 boxes
    ##amount_bboxes = {0:3, 1:5}

    amount_bboxes = Counter([gt[0] for gt in ground_truths])

    for key, val in amount_bboxes.items():
      amount_bboxes[key] = torch.zeros(val)

    detections.sort(key=lambda x: x[2], reverse=True)
    TP = torch.zeros((len(detections)))
    FP = torch.zeros((len(detections)))
    total_true_bboxes = len(ground_truths)

    for detection_idx, detection in enumerate(detections):
      ground_truth_img = [bbox for bbox in ground_truths if bbox[0] == detection[0]]

      num_gts = len(ground_truth_img)
      best_iou = 0

      for idx, gt in enumerate(ground_truth_img):
        iou = intersection_over_union(
            torch.tensor(detection[3:]),
            torch.tensor(gt[3:]),
            box_format=box_format,
        )
        if iou> best_iou:
          best_iou = iou
          best_gt_idx = idx

      if best_iou > iou_threshold:
        if amount_bboxes[detection[0]][best_gt_idx] == 0:
            TP[detection_idx] = 1
            amount_bboxes[detection[0]][best_gt_idx] = 1
        else:
          FP[detection_idx] = 1
      else:
        FP[detection_idx] = 1

    if total_true_bboxes == 0:
       continue
    TP_cumsum = torch.cumsum(TP, dim=0)
    FP_cumsum = torch.cumsum(FP, dim=0)
    recalls = TP_cumsum / (total_true_bboxes + epsilon)
    precisions = TP_cumsum/ (TP_cumsum + FP_cumsum + epsilon)
    precisions = torch.cat((torch.tensor([1]), precisions))
    recalls = torch.cat((torch.tensor([0]), recalls))
    average_precisions.append(torch.trapz(precisions, recalls))

  return sum(average_precisions) / len(average_precisions)

import torch
from collections import Counter


def mean_average_precision(pred_boxes, true_boxes, iou_threshold=0.5, box_format="corners", num_classes=20):
    average_precisions = []
    epsilon = 1e-6

    for c in range(num_classes):
        detections = []
        ground_truths = []

        for detection in pred_boxes:
            # Assuming detection format is [image_idx, class_id, confidence, ...]
            if len(detection) > 1 and detection[1] == c:
                detections.append(detection)

        for true_box in true_boxes:
             # Assuming true_box format is [image_idx, class_id, ...]
            if len(true_box) > 1 and true_box[1] == c:
                ground_truths.append(true_box)

        # Check if there are any true positives for this class
        if not ground_truths:
            continue # Skip this class if no ground truth boxes exist

        amount_bboxes = Counter([gt[0] for gt in ground_truths])
        for key, val in amount_bboxes.items():
            amount_bboxes[key] = torch.zeros(val)

        detections.sort(key=lambda x: x[2], reverse=True) # Sort by confidence
        TP = torch.zeros((len(detections)))
        FP = torch.zeros((len(detections)))
        total_true_bboxes = len(ground_truths)

        for detection_idx, detection in enumerate(detections):
            # Find ground truth boxes for the current image
            ground_truth_img = [bbox for bbox in ground_truths if bbox[0] == detection[0]]

            num_gts = len(ground_truth_img)
            best_iou = 0
            best_gt_idx = -1

            # Iterate through ground truth boxes for the current image to find the best match
            for idx, gt in enumerate(ground_truth_img):
                iou = intersection_over_union(
                    torch.tensor(detection[3:]), # Assuming bounding box starts at index 3
                    torch.tensor(gt[2:]),        # Assuming bounding box starts at index 2 for true_boxes
                    box_format=box_format,
                )
                if iou > best_iou:
                    best_iou = iou
                    best_gt_idx = idx

            # Check if a ground truth box was found and if the IoU is above the threshold
            if best_gt_idx != -1 and best_iou > iou_threshold:
                # Check if the matched ground truth box has already been detected
                if amount_bboxes[detection[0]][best_gt_idx] == 0:
                    TP[detection_idx] = 1
                    amount_bboxes[detection[0]][best_gt_idx] = 1
                else:
                    FP[detection_idx] = 1 # Detected a ground truth box that was already matched
            else:
                FP[detection_idx] = 1 # No ground truth box found or IoU below threshold

        if total_true_bboxes == 0:
           continue # Should be caught by the initial check, but good to have

        TP_cumsum = torch.cumsum(TP, dim=0)
        FP_cumsum = torch.cumsum(FP, dim=0)
        recalls = TP_cumsum / (total_true_bboxes + epsilon)
        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)

        # Add (0, 1) point to the PR curve
        precisions = torch.cat((torch.tensor([1.0]), precisions))
        recalls = torch.cat((torch.tensor([0.0]), recalls))

        # Calculate AP using the trapezoidal rule
        ap = torch.trapz(precisions, recalls)
        average_precisions.append(ap)

    if len(average_precisions) == 0:
        return torch.tensor(0.0)

    return sum(average_precisions) / len(average_precisions)

pred_boxes = [
    [0, 0, 0.9, 10, 10, 50, 50],   # High-confidence correct prediction
    [0, 0, 0.6, 12, 12, 48, 48],   # Overlapping, should be suppressed
    [1, 0, 0.95, 100, 100, 150, 150]  # Correct prediction in image 1
]

true_boxes = [
    [0, 0, 10, 10, 50, 50],   # Ground truth in image 0
    [1, 0, 100, 100, 150, 150]  # Ground truth in image 1
]

map_score = mean_average_precision(pred_boxes, true_boxes, iou_threshold=0.5, box_format="corners", num_classes=1)
print(f"mAP@0.5: {map_score:.4f}")

